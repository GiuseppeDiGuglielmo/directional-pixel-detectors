{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8391fa-659e-448d-bc55-8f6c207a2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "#import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import Input, Activation\n",
    "from qkeras import *\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddbe3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h5 style=\"text-align: center;\">{title}</h5>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae779ee",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'origin_'\n",
    "#base_dir = 'data/oct4_MCwithQuantInputs'\n",
    "\n",
    "dataset = 'balanced_'\n",
    "base_dir = 'data/balancedOct27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12180123-80b5-44e4-bd55-606f9fefc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(base_dir + '/InputTrainSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928faac-c2d6-4345-88ef-6e714d8f2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(base_dir + '/labelsTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90e2bb-9f16-4a05-b309-07b0ad58eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(base_dir + '/InputTestSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c52bf-e171-4bb8-a715-650c0bb1fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(base_dir + '/labelsTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150ba39-5d91-4633-b6cd-b1ecd0b3ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1.values#[:,:13]\n",
    "X_test = df3.values#[:,:13]\n",
    "\n",
    "y_train = df2.values\n",
    "y_test = df4.values\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 0)\n",
    "\n",
    "print('Trainig set shape         :', X_train.shape) \n",
    "print('Trainig set shape (labels):', y_train.shape)\n",
    "print('Test set shape:           :', X_test.shape)\n",
    "print('Test set shape (labels)   :', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "771b1420",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_train without outliers\")\n",
    "_ = plt.boxplot(X_train, showfliers=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d1ef494",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_train with outliers\")\n",
    "_ = plt.boxplot(X_train, showfliers=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae53d615",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_test without outliers\")\n",
    "_ = plt.boxplot(X_test, showfliers=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03d5c950",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_test with outliers\")\n",
    "_ = plt.boxplot(X_test, showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df3]\n",
    "\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9298756",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.title(\"dataset with outliers\")\n",
    "_ = plt.boxplot(df.values, showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56731637",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.title(\"dataset without outliers\")\n",
    "_ = plt.boxplot(df.values, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0047eb",
   "metadata": {},
   "source": [
    "#### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e74612",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a3846",
   "metadata": {},
   "source": [
    "### Scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = ''\n",
    "\n",
    "# Disabling scaling will simplify the hardware design\n",
    "scale = False\n",
    "\n",
    "if scale:\n",
    "    scaling = 'scaling_'\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "    X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "else:\n",
    "    scaling = 'noscaling_'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef88043a",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_train without outliers\")\n",
    "_ = plt.boxplot(X_train, showfliers=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67f158f3",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_train with outliers\")\n",
    "_ = plt.boxplot(X_train, showfliers=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca5ffab3",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_test without outliers\")\n",
    "_ = plt.boxplot(X_test, showfliers=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c9d2f29",
   "metadata": {},
   "source": [
    "_ = plt.title(\"X_test with outliers\")\n",
    "_ = plt.boxplot(X_test, showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv('csv/' + dataset + scaling + 'InputTrainSetScale.csv',index=False)\n",
    "pd.DataFrame(X_test).to_csv('csv/' + dataset + scaling + 'InputTestSetScale.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed1ee5",
   "metadata": {},
   "source": [
    "#### Visualize dataset post-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845eb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafeb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "max_value_X_train = np.max(X_train)\n",
    "min_value_X_train = np.min(X_train)\n",
    "max_value_X_test = np.max(X_test)\n",
    "min_value_X_test = np.min(X_test)\n",
    "\n",
    "log2_max_value_X_train = int(np.ceil(math.log2(np.abs(max_value_X_train))))\n",
    "#log2_min_value_X_train = int(np.ceil(math.log2(np.abs(min_value_X_train))))\n",
    "log2_max_value_X_test = int(np.ceil(math.log2(np.abs(max_value_X_test))))\n",
    "#log2_min_value_X_test = int(np.ceil(math.log2(np.abs(min_value_X_test))))\n",
    "\n",
    "print('X_train: max=', max_value_X_train, ', log2(max)=', log2_max_value_X_train, ', min=', min_value_X_train)\n",
    "print('X_test: max=', max_value_X_test, ', log2(max)=', log2_max_value_X_test, ', min=', min_value_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14b727",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672edbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = pd.get_dummies(df2['ptLabel'])\n",
    "y_test_oh = pd.get_dummies(df4['ptLabel'])\n",
    "\n",
    "y_train_oh.to_csv(\"csv/\" + dataset + \"labelsTrainOH.csv\",index=False)\n",
    "y_test_oh.to_csv(\"csv/\" + dataset + \"labelsTestOH.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side(pd.DataFrame(y_test[:5]), pd.DataFrame(y_test_oh[:5]), titles=['Prediction','One-hot encoding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef817d",
   "metadata": {},
   "source": [
    "## Model (Keras)\n",
    "\n",
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6472f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893e573",
   "metadata": {},
   "source": [
    "#### d128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape, name=\"input\")\n",
    "    x = Dense(128, name=\"dense1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = Activation(\"relu\", name=\"relu1\")(x)\n",
    "    x = Dense(3, name=\"dense2\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "models['d128'] = {'prefix': dataset + scaling + 'keras_d128_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f544e",
   "metadata": {},
   "source": [
    "#### d64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape, name=\"input\")\n",
    "    x = Dense(64, name=\"dense1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = Activation(\"relu\", name=\"relu1\")(x)\n",
    "    x = Dense(3, name=\"dense2\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "models['d64'] = {'prefix': dataset + scaling + 'keras_d64_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114951a2",
   "metadata": {},
   "source": [
    "#### d64_d32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape, name=\"input\")\n",
    "    x = Dense(64, name=\"dense1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = Activation(\"relu\", name=\"relu1\")(x)\n",
    "    x = Dense(32, name=\"dense2\")(x)\n",
    "    x = Activation(\"relu\", name=\"relu2\")(x)\n",
    "    x = Dense(3, name=\"dense3\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "models['d64_d32'] = {'prefix': dataset + scaling + 'keras_d64_d32_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e9115",
   "metadata": {},
   "source": [
    "#### d32_d32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = dataset + scaling + 'keras_d32_d32_'\n",
    "\n",
    "def CreateModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape, name=\"input\")\n",
    "    x = Dense(32, name=\"dense1\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = Activation(\"relu\", name=\"relu1\")(x)\n",
    "    x = Dense(32, name=\"dense2\")(x)\n",
    "    x = Activation(\"relu\", name=\"relu2\")(x)\n",
    "    x = Dense(3, name=\"dense3\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "models['d32_d32'] = {'prefix': dataset + scaling + 'keras_d32_d32_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf9fd83",
   "metadata": {},
   "source": [
    "#### Create and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037bf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = models['d128']['prefix']\n",
    "model_def = models['d128']['def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42427723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_def(X_train.shape[1:], y_train.shape[-1])\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # default from_logits=False\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb5cce",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddbaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed975c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model/' + prefix + 'model.h5'\n",
    "\n",
    "history = None\n",
    "if train_and_save:\n",
    "    es = EarlyStopping(monitor='val_sparse_categorical_accuracy', \n",
    "                       mode='max', # don't minimize the accuracy!\n",
    "                       patience=10,\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=150, \n",
    "                    batch_size=1024,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=0)\n",
    "    \n",
    "    model.save(model_file)\n",
    "print(model_file)\n",
    "co = {}\n",
    "utils._add_supported_quantized_objects(co)\n",
    "model = tf.keras.models.load_model(model_file, custom_objects=co)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf6b82",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309677e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_and_save:\n",
    "    history_dict = history.history\n",
    "    loss_values = history_dict['loss'] \n",
    "    val_loss_values = history_dict['val_loss'] \n",
    "    epochs = range(1, len(loss_values) + 1) \n",
    "    plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + prefix + 'loss.png')\n",
    "else:\n",
    "    from PIL import Image\n",
    "\n",
    "    img = Image.open('images/' + prefix + 'loss.png')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ede71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_and_save:\n",
    "    acc = history.history['sparse_categorical_accuracy']\n",
    "    val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'orange', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    #np.max(val_acc)\n",
    "    plt.savefig('images/' + prefix + 'accuracy.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    from PIL import Image\n",
    "    #from os.path import exists\n",
    "\n",
    "    img = Image.open('images/' + prefix + 'accuracy.png')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94799472",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test) \n",
    "predictionsFiles = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94c1cf0a",
   "metadata": {},
   "source": [
    "predictionsFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictionsFiles).to_csv(\"csv/\" + prefix + \"predictionsFiles.csv\", header='predict', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2184f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).to_csv(\"csv/\" + prefix + \"true.csv\", header='true', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c53c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss (Keras):\", score[0])\n",
    "print(\"Test accuracy (Keras):\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predictionsFiles)\n",
    "disp.figure_.suptitle(\"Multiclassifier Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "plt.savefig('images/' + prefix + 'confusionMatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee7f4e",
   "metadata": {},
   "source": [
    "## Model (QKeras)\n",
    "\n",
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodels = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2dd0bd",
   "metadata": {},
   "source": [
    "#### d128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af05867-d2f2-4be1-9bd1-f179487a47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = scaling + 'qkeras_d128'\n",
    "# def CreateQModel(shape, nb_classes):\n",
    "#     x = x_in = Input(shape)\n",
    "#     x = QDense(128,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense1\")(x)\n",
    "#     x = keras.layers.BatchNormalization()(x)\n",
    "#     x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "#     x = QDense(3,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense2\")(x)\n",
    "#     x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "#     model = Model(inputs=x_in, outputs=x)\n",
    "#     return model\n",
    "\n",
    "# Fold BatchNormalization in QDense\n",
    "def CreateQModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape)\n",
    "    x = QDenseBatchnorm(128,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense1\")(x)\n",
    "    x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "    x = QDense(3,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense2\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "qmodels['d128'] = {'prefix': dataset + scaling + 'qkeras_foldbatchnorm_d128_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bf3d9",
   "metadata": {},
   "source": [
    "#### d64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ae97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = scaling + 'qkeras_d64'\n",
    "# def CreateQModel(shape, nb_classes):\n",
    "#     x = x_in = Input(shape)\n",
    "#     x = QDense(128,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense1\")(x)\n",
    "#     x = keras.layers.BatchNormalization()(x)\n",
    "#     x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "#     x = QDense(3,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense2\")(x)\n",
    "#     x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "#     model = Model(inputs=x_in, outputs=x)\n",
    "#     return model\n",
    "\n",
    "# Fold BatchNormalization in QDense\n",
    "def CreateQModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape)\n",
    "    x = QDenseBatchnorm(64,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense1\")(x)\n",
    "    x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "    x = QDense(3,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense2\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "qmodels['d64'] = {'prefix': dataset + scaling + 'qkeras_foldbatchnorm_d64_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656dadb4",
   "metadata": {},
   "source": [
    "#### d64_d32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a49c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = scaling + 'qkeras_d64_d32_'\n",
    "# def CreateQModel(shape, nb_classes):\n",
    "#     x = x_in = Input(shape)\n",
    "#     x = QDense(128,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense1\")(x)\n",
    "#     x = keras.layers.BatchNormalization()(x)\n",
    "#     x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "#     x = QDense(3,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense2\")(x)\n",
    "#     x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "#     model = Model(inputs=x_in, outputs=x)\n",
    "#     return model\n",
    "\n",
    "# Fold BatchNormalization in QDense\n",
    "def CreateQModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape)\n",
    "    x = QDenseBatchnorm(64,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense1\")(x)\n",
    "    x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "    x = QDense(32,\n",
    "         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "         name=\"dense2\")(x)\n",
    "    x = QActivation(\"quantized_relu(10,0)\", name=\"relu2\")(x)\n",
    "    x = QDense(3,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense3\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "qmodels['d64_d32'] = {'prefix': dataset + scaling + 'qkeras_foldbatchnorm_d64_32_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1498dd",
   "metadata": {},
   "source": [
    "#### d32_d32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = scaling + 'qkeras_d64_d32_'\n",
    "# def CreateQModel(shape, nb_classes):\n",
    "#     x = x_in = Input(shape)\n",
    "#     x = QDense(128,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense1\")(x)\n",
    "#     x = keras.layers.BatchNormalization()(x)\n",
    "#     x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "#     x = QDense(3,\n",
    "#         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "#         name=\"dense2\")(x)\n",
    "#     x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "#     model = Model(inputs=x_in, outputs=x)\n",
    "#     return model\n",
    "\n",
    "# Fold BatchNormalization in QDense\n",
    "prefix = dataset + scaling + 'qkeras_foldbatchnorm_d32_d32_'\n",
    "def CreateQModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape)\n",
    "    x = QDenseBatchnorm(32,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense1\")(x)\n",
    "    x = QActivation(\"quantized_relu(10,0)\", name=\"relu1\")(x)\n",
    "    x = QDense(32,\n",
    "         kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "         name=\"dense2\")(x)\n",
    "    x = QActivation(\"quantized_relu(10,0)\", name=\"relu2\")(x)\n",
    "    x = QDense(3,\n",
    "        kernel_quantizer=quantized_bits(5,0,alpha=1), bias_quantizer=quantized_bits(5,0,alpha=1),\n",
    "        name=\"dense3\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "qmodels['d32_d32'] = {'prefix': dataset + scaling + 'qkeras_foldbatchnorm_d32_32_', 'def': CreateModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b18a5",
   "metadata": {},
   "source": [
    "#### Create and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c95f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = qmodels['d128']['prefix']\n",
    "model_def = models['d128']['def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8610bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_def(X_train.shape[1:], y_train.shape[-1])\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # default from_logits=False\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd850c3",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720ce89-2eae-4016-a7c2-955ae4bbaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model/' + prefix + 'model.h5'\n",
    "\n",
    "history = None\n",
    "if train_and_save:\n",
    "    es = EarlyStopping(monitor='val_sparse_categorical_accuracy', \n",
    "                                   mode='max', # don't minimize the accuracy!\n",
    "                                   patience=10,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=150, \n",
    "                    batch_size=1024,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=0)\n",
    "    \n",
    "    model.save(model_file)\n",
    "    \n",
    "co = {}\n",
    "utils._add_supported_quantized_objects(co)\n",
    "model = tf.keras.models.load_model(model_file, custom_objects=co)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19db391b",
   "metadata": {},
   "source": [
    "from keras_sequential_ascii import keras2ascii\n",
    "keras2ascii(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a04ec9",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4c82a-85d8-4e6c-9396-5ea7ec79e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_and_save:\n",
    "    history_dict = history.history\n",
    "    loss_values = history_dict['loss'] \n",
    "    val_loss_values = history_dict['val_loss'] \n",
    "    epochs = range(1, len(loss_values) + 1) \n",
    "    plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + prefix + 'loss.png')\n",
    "else:\n",
    "    from PIL import Image\n",
    "\n",
    "    img = Image.open('images/' + prefix + 'loss.png')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4da634-9a07-4808-93f1-afc1428c08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_and_save:\n",
    "    acc = history.history['sparse_categorical_accuracy']\n",
    "    val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'orange', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    #np.max(val_acc)\n",
    "    plt.savefig('images/' + prefix + 'accuracy.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    from PIL import Image\n",
    "    #from os.path import exists\n",
    "\n",
    "    img = Image.open('images/' + prefix + 'accuracy.png')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378681c-a72c-4380-84bd-9fcf5b782038",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test) \n",
    "predictionsFiles = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e22a93b",
   "metadata": {},
   "source": [
    "predictionsFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091327bd-28ed-4570-8f00-9315e209bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictionsFiles).to_csv(\"csv/\" + prefix + \"predictionsFiles.csv\", header='predict', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa23cc3-3f30-4cd4-85e5-ae6064869378",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).to_csv(\"csv/\" + prefix + \"true.csv\", header='true', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf53631-bfae-4276-9400-30bbf6bc5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss (QKeras):\", score[0])\n",
    "print(\"Test accuracy (QKeras):\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf8385-5618-4176-aba4-f1fc0c459df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predictionsFiles)\n",
    "disp.figure_.suptitle(\"Multiclassifier Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "plt.savefig('images/' + prefix + 'confusionMatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f0b53",
   "metadata": {},
   "source": [
    "## Hardware translation\n",
    "\n",
    "### hls4ml configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "prefix = 'hls4ml_' + prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hls4ml ver.', hls4ml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = '/opt/xilinx/Vivado/2019.1/bin:' + os.environ['PATH']\n",
    "def is_tool(name):\n",
    "    from distutils.spawn import find_executable\n",
    "    return find_executable(name) is not None\n",
    "\n",
    "print('-----------------------------------')\n",
    "if not is_tool('vivado_hls'):\n",
    "    print('Xilinx Vivado HLS is NOT in the PATH')\n",
    "else:\n",
    "    print('Xilinx Vivado HLS is in the PATH')\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "# hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(\n",
    "#     layers=['Activation'],\n",
    "#     rounding_mode='AP_RND_CONV',\n",
    "#     saturation_mode='AP_SAT')\n",
    "\n",
    "hconfig = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "hconfig['Model']['Precision'] = 'ap_fixed<16,8>'\n",
    "\n",
    "# Input\n",
    "hconfig['LayerName']['input_1']['Precision']['result'] = 'ap_fixed<16,8>'\n",
    "\n",
    "# Dense\n",
    "hconfig['LayerName']['dense1']['accum_t'] = 'ap_fixed<16,8>'\n",
    "hconfig['LayerName']['dense1']['Precision']['result'] = 'ap_fixed<16,8>'\n",
    "\n",
    "# ReLU\n",
    "#hconfig['LayerName']['relu1']['Precision']['result'] = 'ap_fixed<10,0>'\n",
    "\n",
    "# Dense\n",
    "hconfig['LayerName']['dense2']['accum_t'] = 'ap_fixed<16,8>'\n",
    "hconfig['LayerName']['dense2']['Precision']['result'] = 'ap_fixed<16,8>'\n",
    "\n",
    "# # ReLU\n",
    "# #hconfig['LayerName']['relu2']['Precision']['result'] = 'ap_fixed<10,0>'\n",
    "\n",
    "# # Dense\n",
    "# hconfig['LayerName']['dense3']['accum_t'] = 'ap_fixed<16,8>'\n",
    "# hconfig['LayerName']['dense3']['Precision']['result'] = 'ap_fixed<16,8>'\n",
    "\n",
    "# SoftMax\n",
    "# #hconfig['LayerName']['softmax']['Precision'] = 'ap_fixed<128,64>'\n",
    "\n",
    "hconfig['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "hconfig['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "hconfig['LayerName']['softmax']['Precision'] = 'ap_fixed<16,6>'\n",
    "\n",
    "# Required for the folding of BatchNormalization\n",
    "#hconfig['SkipOptimizers'] = ['relu_merge']\n",
    "\n",
    "for layer in hconfig['LayerName'].keys():\n",
    "    hconfig['LayerName'][layer]['Trace'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82919641",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.print_dict(hconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmodel = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                    clock_period=10.0,\n",
    "                                                    hls_config=hconfig,\n",
    "                                                    output_dir=prefix + 'vivado_prj',\n",
    "                                                    part='XC7A100T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91684a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hmodel, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e86dd8",
   "metadata": {},
   "source": [
    "### Bit-accurate simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpreds, htrace = hmodel.trace(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d814fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in htrace.keys():\n",
    "    plt.figure()\n",
    "    klayer = layer\n",
    "    if '_alpha' in layer:\n",
    "        klayer = layer.replace('_alpha', '')\n",
    "    plt.scatter(htrace[layer].flatten(), trace[klayer].flatten(), s=0.2)\n",
    "    min_x = min(np.amin(htrace[layer]), np.amin(trace[klayer]))\n",
    "    max_x = max(np.amax(htrace[layer]), np.amax(trace[klayer]))\n",
    "    plt.plot([min_x, max_x], [min_x, max_x], c='gray')\n",
    "    plt.xlabel('hls4ml {}'.format(layer))\n",
    "    plt.ylabel('QKeras {}'.format(klayer))\n",
    "    plt.savefig(os.path.join(prefix + 'vivado_prj', 'profiling_{}.png'.format(layer)), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5363d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in hconfig['LayerName'].keys():\n",
    "    hconfig['LayerName'][layer]['Trace'] = False\n",
    "\n",
    "hmodel = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                    clock_period=10.0,\n",
    "                                                    hls_config=hconfig,\n",
    "                                                    output_dir=prefix + 'vivado_prj',\n",
    "                                                    part='XC7A100T')\n",
    "\n",
    "hmodel.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpreds = hmodel.predict(np.ascontiguousarray(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e377c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('-----------------------------------')\n",
    "print(\"QKeras accuracy: {:.4f}%\".format(100*accuracy_score(np.argmax(y_test_oh.values, axis=1), np.argmax(preds, axis=1))))\n",
    "print(\"hls4ml accuracy: {:.4f}%\".format(100*accuracy_score(np.argmax(y_test_oh.values, axis=1), np.argmax(hpreds, axis=1))))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dacd52e",
   "metadata": {},
   "source": [
    "for i in range(5):\n",
    "    print('X[{}], {}'.format(i, X_test[i]))\n",
    "    print('golden y[{}]'.format(i), y_test[i])\n",
    "    print('onehot y[{}]'.format(i), y_test_oh.values[i])\n",
    "    print('QKeras y[{}]'.format(i), preds[i])\n",
    "    print('hls4ml y[{}]'.format(i), hpreds[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side(pd.DataFrame(X_test[:5]), titles=['Scaled input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47771f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side(pd.DataFrame(y_test[:5]),\n",
    "                     pd.DataFrame(y_test_oh[:5]),\n",
    "                     pd.DataFrame(preds[:5]),\n",
    "                     pd.DataFrame(hpreds[:5]),\n",
    "                     titles=['Expected prediction','Expected prediction (one-hot enc.)', 'QKeras prediction', 'hls4ml prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6495d",
   "metadata": {},
   "source": [
    "### Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3930a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell applies a patch/workaround necessary with some version of hls4ml.\n",
    "# It is a poor solution, but it works. Edit patches/project.tcl if you make any change\n",
    "# in this notebook.\n",
    "import shutil\n",
    "_ = shutil.copyfile('patches/project.tcl', prefix + 'vivado_prj/project.tcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = hmodel.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------------------------')\n",
    "#print(results) # Print hashmap\n",
    "hls_results=results\n",
    "#['CSynthesisReport'] \n",
    "print(\"Estimated Clock Period: {} ns\".format(hls_results['EstimatedClockPeriod']))\n",
    "print(\"Best/Worst Latency:     {} / {}\".format(hls_results['BestLatency'], hls_results['WorstLatency']))\n",
    "print(\"Interval Min/Max:       {} / {}\".format(hls_results['IntervalMin'], hls_results['IntervalMax']))\n",
    "print(\"BRAM_18K:               {}, {:0.1f}% (Aval. {})\".format(hls_results['BRAM_18K'], int(hls_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "print(\"DSP48E:                 {}, {:0.1f}% (Aval. {})\".format(hls_results['DSP48E'], int(hls_results['DSP48E'])*100.0/int(hls_results['AvailableDSP48E']), hls_results['AvailableDSP48E']))\n",
    "print(\"FF:                     {}, {:0.1f}% (Aval. {})\".format(hls_results['FF'], int(hls_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "print(\"LUT:                    {}, {:0.1f}% (Aval. {})\".format(hls_results['LUT'], int(hls_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "#print(\"URAM:                   {}, {} (Aval. {})\".format(hls_results['URAM'], int(hls_results['URAM'])*100.0/int(hls_results['AvailableURAM']), hls_results['AvailableURAM']))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d65f3bb",
   "metadata": {},
   "source": [
    "hmodel = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                    clock_period=10.0,\n",
    "                                                    hls_config=hconfig,\n",
    "                                                    output_dir='hls4ml_catapult_prj',\n",
    "                                                    backend='Catapult')\n",
    "\n",
    "hmodel.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
