{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f17246",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f7870",
   "metadata": {},
   "source": [
    "## Library setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69082377",
   "metadata": {},
   "source": [
    "Disable some console warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafd49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f6a50",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175cf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae779ee",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b0a99",
   "metadata": {},
   "source": [
    "### QKeras model (HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace79c9",
   "metadata": {},
   "source": [
    "<p style=\"background-color:Tomato;\"><b>DO NOT USE HDF5 FOR THIS ANALYSIS. MODELS WITH BATCHNORM FOLDING GET SAVED WITHOUT AN EXPLICIT FOLDING SO RESULTS MAY BE MISLEADING!</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94b5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'models'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb784431",
   "metadata": {},
   "source": [
    "model_ids = [    \n",
    "    'ds8l0_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l1_noscaling_qkeras_foldbatchnorm_d64',    \n",
    "    'ds8l2_noscaling_qkeras_foldbatchnorm_d64',    \n",
    "    'ds8l3_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l4_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l5_noscaling_qkeras_foldbatchnorm_d64',   \n",
    "    'ds8l6_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l7_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l8_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l9_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l10_noscaling_qkeras_foldbatchnorm_d64',\n",
    "    'ds8l11_noscaling_qkeras_foldbatchnorm_d64',   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2967b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_qmodel_l0 = h5py.File(MODEL_DIR + '/ds8l0_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l0 = h5py.File(MODEL_DIR + '/ds8l0_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l1 = h5py.File(MODEL_DIR + '/ds8l1_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l1 = h5py.File(MODEL_DIR + '/ds8l1_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l2 = h5py.File(MODEL_DIR + '/ds8l2_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l2 = h5py.File(MODEL_DIR + '/ds8l2_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l3 = h5py.File(MODEL_DIR + '/ds8l3_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l3 = h5py.File(MODEL_DIR + '/ds8l3_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l4 = h5py.File(MODEL_DIR + '/ds8l4_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l4 = h5py.File(MODEL_DIR + '/ds8l4_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l5 = h5py.File(MODEL_DIR + '/ds8l5_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l5 = h5py.File(MODEL_DIR + '/ds8l5_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l6 = h5py.File(MODEL_DIR + '/ds8l6_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l6 = h5py.File(MODEL_DIR + '/ds8l6_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l7 = h5py.File(MODEL_DIR + '/ds8l7_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l7 = h5py.File(MODEL_DIR + '/ds8l7_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l8 = h5py.File(MODEL_DIR + '/ds8l8_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l8 = h5py.File(MODEL_DIR + '/ds8l8_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l9 = h5py.File(MODEL_DIR + '/ds8l9_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l9 = h5py.File(MODEL_DIR + '/ds8l9_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l10 = h5py.File(MODEL_DIR + '/ds8l10_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l10 = h5py.File(MODEL_DIR + '/ds8l10_noscaling_qkeras_d64_model.h5', 'r')\n",
    "# hf_qmodel_l11 = h5py.File(MODEL_DIR + '/ds8l11_noscaling_qkeras_d64_model_q_weights.h5', 'r')\n",
    "# hf_model_l11 = h5py.File(MODEL_DIR + '/ds8l11_noscaling_qkeras_d64_model.h5', 'r')\n",
    "\n",
    "hf_model_l0  = h5py.File(MODEL_DIR +  '/ds8l0_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l1  = h5py.File(MODEL_DIR +  '/ds8l1_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l2  = h5py.File(MODEL_DIR +  '/ds8l2_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l3  = h5py.File(MODEL_DIR +  '/ds8l3_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l4  = h5py.File(MODEL_DIR +  '/ds8l4_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l5  = h5py.File(MODEL_DIR +  '/ds8l5_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l6  = h5py.File(MODEL_DIR +  '/ds8l6_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l7  = h5py.File(MODEL_DIR +  '/ds8l7_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l8  = h5py.File(MODEL_DIR +  '/ds8l8_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l9  = h5py.File(MODEL_DIR +  '/ds8l9_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l10 = h5py.File(MODEL_DIR + '/ds8l10_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')\n",
    "hf_model_l11 = h5py.File(MODEL_DIR + '/ds8l11_noscaling_qkeras_foldbatchnorm_d64_model.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137282eb",
   "metadata": {},
   "source": [
    "#### Visualize QKeras model (HDF5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75504d7f",
   "metadata": {},
   "source": [
    "#print(hf_qmodel_l0.keys())\n",
    "\n",
    "print(hf_model_l0.keys())\n",
    "print(hf_model_l0['model_weights'].keys())\n",
    "print(hf_model_l0['model_weights']['dense1'].keys())\n",
    "print(hf_model_l0['model_weights']['dense1']['dense1'].keys())\n",
    "print(hf_model_l0['model_weights']['dense2'].keys())\n",
    "print(hf_model_l0['model_weights']['dense2']['dense2'].keys())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f84ea236",
   "metadata": {},
   "source": [
    "# model_l0_q_w0 = hf_qmodel_l0['dense1']['dense1']['kernel:0']\n",
    "# model_l0_q_b0 = hf_qmodel_l0['dense1']['dense1']['bias:0']\n",
    "# model_l0_q_w1 = hf_qmodel_l0['dense2']['dense2']['kernel:0']\n",
    "# model_l0_q_b1 = hf_qmodel_l0['dense2']['dense2']['bias:0']\n",
    "\n",
    "model_l0_w0 = hf_model_l0['model_weights']['dense1']['dense1']['kernel:0']\n",
    "model_l0_b0 = hf_model_l0['model_weights']['dense1']['dense1']['bias:0']\n",
    "model_l0_w1 = hf_model_l0['model_weights']['dense2']['dense2']['kernel:0']\n",
    "model_l0_b1 = hf_model_l0['model_weights']['dense2']['dense2']['bias:0']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a81bbb0",
   "metadata": {},
   "source": [
    "# print('Model l0 Q dense1 w[0][0]', model_l0_q_w0[0][0])\n",
    "# print('Model l0 Q dense1 w[0][1]', model_l0_q_w0[0][1])\n",
    "# print('Model l0 Q dense1 w[0][2]', model_l0_q_w0[0][2])\n",
    "# print('Model l0 Q dense1 w[0][3]', model_l0_q_w0[0][3])\n",
    "# print('Model l0 Q dense1 w[0][4]', model_l0_q_w0[0][4])\n",
    "# print('Model l0 Q dense1 w[0][5]', model_l0_q_w0[0][5])\n",
    "# print('...')\n",
    "# print('Model l0 Q dense1 w[12][63]', model_l0_q_w0[11][63])\n",
    "\n",
    "print('')\n",
    "print('Model l0 dense1 w[0][0]', model_l0_w0[0][0])\n",
    "print('Model l0 dense1 w[0][1]', model_l0_w0[0][1])\n",
    "print('Model l0 dense1 w[0][2]', model_l0_w0[0][2])\n",
    "print('Model l0 dense1 w[0][3]', model_l0_w0[0][3])\n",
    "print('Model l0 dense1 w[0][4]', model_l0_w0[0][4])\n",
    "print('Model l0 dense1 w[0][5]', model_l0_w0[0][5])\n",
    "print('...')\n",
    "print('Model l0 dense1 w[11][63]', model_l0_w0[11][63])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62c29e34",
   "metadata": {},
   "source": [
    "for i in range(model_l0_w0.shape[0]):\n",
    "    for j in range(model_l0_w0.shape[1]):\n",
    "        print('[{}][{}] {}'.format(i, j, model_l0_w0[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937402c8",
   "metadata": {},
   "source": [
    "### hls4ml model (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf03e5",
   "metadata": {},
   "source": [
    "Collect data from the .csv files (essentially the .txt files of an hls4ml projects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a008a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('weights.hdf5', 'w') as hf:\n",
    "    for i in range(12):\n",
    "        # df_dense1_w = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_d64_vivado_prj/firmware/weights/w2.txt', header=None)\n",
    "        # df_dense1_b = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_d64_vivado_prj/firmware/weights/b2.txt', header=None)\n",
    "        # df_dense2_w = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_d64_vivado_prj/firmware/weights/w6.txt', header=None)\n",
    "        # df_dense2_b = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_d64_vivado_prj/firmware/weights/b6.txt', header=None)\n",
    "        \n",
    "        df_dense1_w = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_foldbatchnorm_d64_vivado_prj/firmware/weights/w2.txt', header=None)\n",
    "        df_dense1_b = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_foldbatchnorm_d64_vivado_prj/firmware/weights/b2.txt', header=None)\n",
    "        df_dense2_w = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_foldbatchnorm_d64_vivado_prj/firmware/weights/w5.txt', header=None)\n",
    "        df_dense2_b = pd.read_csv('hls4ml_ds8l' + str(i) + '_noscaling_qkeras_foldbatchnorm_d64_vivado_prj/firmware/weights/b5.txt', header=None)\n",
    "\n",
    "        dset = hf.create_dataset('/l' + str(i) + '/dense1/w', data=df_dense1_w.values[0])\n",
    "        dset = hf.create_dataset('/l' + str(i) + '/dense1/b', data=df_dense1_b.values[0])\n",
    "        dset = hf.create_dataset('/l' + str(i) + '/dense2/w', data=df_dense2_w.values[0])\n",
    "        dset = hf.create_dataset('/l' + str(i) + '/dense2/b', data=df_dense2_b.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af112fb",
   "metadata": {},
   "source": [
    "#### Visualize hls4ml model (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6ee52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['l0', 'l1', 'l10', 'l11', 'l2', 'l3', 'l4', 'l5', 'l6', 'l7', 'l8', 'l9']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('weights.hdf5', 'r') as hf:\n",
    "    print(hf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8948157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"w\": shape (832,), type \"<f8\">\n",
      "<HDF5 dataset \"b\": shape (64,), type \"<f8\">\n",
      "<HDF5 dataset \"w\": shape (192,), type \"<f8\">\n",
      "<HDF5 dataset \"b\": shape (3,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('weights.hdf5', 'r') as hf:\n",
    "    print(hf['/l0/dense1/w'])\n",
    "    print(hf['/l0/dense1/b'])\n",
    "    print(hf['/l0/dense2/w'])\n",
    "    print(hf['/l0/dense2/b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a20653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model l0 dense1 w[0][0] -0.6875\n",
      "Model l0 dense1 w[0][1] -0.3125\n",
      "Model l0 dense1 w[0][2] -0.3125\n",
      "Model l0 dense1 w[0][3] 0.3125\n",
      "Model l0 dense1 w[0][4] 0.0\n",
      "Model l0 dense1 w[0][5] 0.0\n",
      "...\n",
      "Model l0 dense1 w[11][63] 0.125\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('weights.hdf5', 'r') as hf:\n",
    "    print('Model l0 dense1 w[0][0]', hf['/l0/dense1/w'][0])\n",
    "    print('Model l0 dense1 w[0][1]', hf['/l0/dense1/w'][1])\n",
    "    print('Model l0 dense1 w[0][2]', hf['/l0/dense1/w'][2])\n",
    "    print('Model l0 dense1 w[0][3]', hf['/l0/dense1/w'][3])\n",
    "    print('Model l0 dense1 w[0][4]', hf['/l0/dense1/w'][4])\n",
    "    print('Model l0 dense1 w[0][5]', hf['/l0/dense1/w'][5])\n",
    "    print('...')\n",
    "    print('Model l0 dense1 w[11][63]', hf['/l0/dense1/w'][63])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7fdf991",
   "metadata": {},
   "source": [
    "with h5py.File('weights.hdf5', 'r') as hf:\n",
    "    print(hf['/l0/dense1/w'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1ac2e",
   "metadata": {},
   "source": [
    "### Compare QKeras (HDF5) and hls4ml (.csv) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeeeeb9",
   "metadata": {},
   "source": [
    "<p style=\"background-color:Tomato;\"><b>DO NOT COMPARE HDF5 AND CSV DATA. IF THE MODEL HAS BATCHNORM FOLDING THEN IT WILL NOT MATCH.</b></p>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "527ad881",
   "metadata": {},
   "source": [
    "hf = h5py.File('weights.hdf5', 'r')\n",
    "print('Model QKeras/hls4ml l0 dense1 w[0][0] {}/{}'.format(model_l0_w0[0][0],hf['/l0/dense1/w'][0]))\n",
    "print('Model QKeras/hls4ml l0 dense1 w[0][1] {}/{}'.format(model_l0_w0[0][1],hf['/l0/dense1/w'][1]))\n",
    "print('Model QKeras/hls4ml l0 dense1 w[0][2] {}/{}'.format(model_l0_w0[0][2],hf['/l0/dense1/w'][2]))\n",
    "print('Model QKeras/hls4ml l0 dense1 w[0][3] {}/{}'.format(model_l0_w0[0][3],hf['/l0/dense1/w'][3]))\n",
    "print('Model QKeras/hls4ml l0 dense1 w[0][4] {}/{}'.format(model_l0_w0[0][4],hf['/l0/dense1/w'][4]))\n",
    "print('Model QKeras/hls4ml l0 dense1 w[0][5] {}/{}'.format(model_l0_w0[0][5],hf['/l0/dense1/w'][5]))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac43ed",
   "metadata": {},
   "source": [
    "## Check weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94ff6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across 12 models:\n",
      "- Dense1.w: count of weight columns that are the same 0\n",
      "- Dense1.b: count of weight columns that are the same 0\n",
      "- Dense2.w: count of weight columns that are the same 0\n",
      "- Dense2.b: count of weight columns that are the same 0\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('weights.hdf5', 'r') as hf:\n",
    "    df_dense1_w_size = hf['/l0/dense1/w'].shape[0]\n",
    "    df_dense1_b_size = hf['/l0/dense1/b'].shape[0]\n",
    "    df_dense2_w_size = hf['/l0/dense2/w'].shape[0]\n",
    "    df_dense2_b_size = hf['/l0/dense2/b'].shape[0]\n",
    "\n",
    "    N_MODELS = 12\n",
    "\n",
    "    print('Across', N_MODELS, 'models:')\n",
    "\n",
    "    ##\n",
    "    ## Dense 1\n",
    "    ##\n",
    "    total = 0 # count of weight columns that are the same\n",
    "    for i in range(df_dense1_w_size): # for each weight column\n",
    "        c = 0\n",
    "        for j in range(N_MODELS):  # for each model\n",
    "            if (hf['/l' + str(j) + '/dense1/w'][i] == hf['/l0/dense1/w'][i]):\n",
    "                c = c + 1\n",
    "        if (c == N_MODELS):\n",
    "            total = total + 1\n",
    "    print('- Dense1.w: count of weight columns that are the same', total)\n",
    "\n",
    "    total = 0 # count of weight columns that are the same\n",
    "    for i in range(df_dense1_b_size): # for each weight column\n",
    "        c = 0\n",
    "        for j in range(N_MODELS):  # for each model\n",
    "            if (hf['/l' + str(j) + '/dense1/b'][i] == hf['/l0/dense1/b'][i]):\n",
    "                c = c + 1\n",
    "        if (c == N_MODELS):\n",
    "            total = total + 1\n",
    "    print('- Dense1.b: count of weight columns that are the same', total)\n",
    "\n",
    "    ##\n",
    "    ## Dense 2\n",
    "    ##\n",
    "    total = 0 # count of weight columns that are the same\n",
    "    for i in range(df_dense2_w_size): # for each weight column\n",
    "        c = 0\n",
    "        for j in range(N_MODELS):  # for each model\n",
    "            if (hf['/l' + str(j) + '/dense2/w'][i] == hf['/l0/dense2/w'][i]):\n",
    "                c = c + 1\n",
    "        if (c == N_MODELS):\n",
    "            total = total + 1\n",
    "    print('- Dense2.w: count of weight columns that are the same', total)\n",
    "\n",
    "    total = 0 # count of weight columns that are the same\n",
    "    for i in range(df_dense2_b_size): # for each weight column\n",
    "        c = 0\n",
    "        for j in range(N_MODELS):  # for each model\n",
    "            if (hf['/l' + str(j) + '/dense2/b'][i] == hf['/l0/dense2/b'][i]):\n",
    "                c = c + 1\n",
    "        if (c == N_MODELS):\n",
    "            total = total + 1\n",
    "    print('- Dense2.b: count of weight columns that are the same', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9250bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6875 -0.3125 -0.3125  0.3125  0.      0.     -0.1875  0.0625]\n",
      "[-0.25    0.0625 -0.1875  0.125   0.4375  0.125   0.25    0.    ]\n",
      "[ 0.     -0.125   0.     -0.0625  0.     -0.125   0.4375  0.5   ]\n",
      "[ 0.     -0.0625  0.      0.      0.0625 -0.125   0.25    0.125 ]\n",
      "[ 0.0625  0.0625  0.      0.125   0.125   0.     -0.0625  0.3125]\n",
      "[ 0.0625  0.     -0.0625 -0.125   0.     -0.0625  0.0625 -0.0625]\n",
      "[ 0.125   0.      0.125   0.     -0.0625 -0.125   0.0625  0.0625]\n",
      "[ 0.25   -0.0625  0.      0.     -0.125   0.0625 -0.375   0.0625]\n",
      "[ 0.0625  0.      0.125   0.125   0.0625  0.0625 -0.125  -0.0625]\n",
      "[0.     0.0625 0.0625 0.     0.125  0.     0.     0.    ]\n",
      "[ 0.     -0.0625  0.      0.      0.0625 -0.125  -0.0625  0.    ]\n",
      "[0.     0.0625 0.     0.0625 0.0625 0.0625 0.0625 0.1875]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('weights.hdf5', 'r') as hf:\n",
    "    print(hf['/l0/dense1/w'][:8])\n",
    "    print(hf['/l1/dense1/w'][:8])\n",
    "    print(hf['/l2/dense1/w'][:8])\n",
    "    print(hf['/l3/dense1/w'][:8])\n",
    "    print(hf['/l4/dense1/w'][:8])\n",
    "    print(hf['/l5/dense1/w'][:8])\n",
    "    print(hf['/l6/dense1/w'][:8])\n",
    "    print(hf['/l7/dense1/w'][:8])\n",
    "    print(hf['/l8/dense1/w'][:8])\n",
    "    print(hf['/l9/dense1/w'][:8])\n",
    "    print(hf['/l10/dense1/w'][:8])\n",
    "    print(hf['/l11/dense1/w'][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be908036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236.483px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
