{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f683539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, TimeDistributed, LSTM, Conv3D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import CSVLogger\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import copy\n",
    "import glob\n",
    "import fileinput\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#for gpu in gpus:\n",
    " # tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#this run has 768k train, 192k test\n",
    "BATCH_SIZE = 512 \n",
    "EPOCHS = 20\n",
    "NUMBER_TEST_SET = 192000 #will do train/test split before this, and pass already-made sets in\n",
    "TEMPORAL_LENGTH = 8 #use first 8 frames (these are 16 frames in each video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c8344-5431-4530-985c-05149370d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa157e4-fee8-4078-a8ca-36246bb6e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for file in glob.glob('train/Data*.npy'):\n",
    "  input = np.load(file,allow_pickle=True)\n",
    "  train_data.append(input)\n",
    "train_data = np.concatenate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62f35b-3cba-4cd0-a40e-5ae6730856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for file in glob.glob('test/Data*.npy'):\n",
    "  input = np.load(file,allow_pickle=True)\n",
    "  test_data.append(input)\n",
    "test_data = np.concatenate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed09b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08067eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total number of test samples:',len(test_data))\n",
    "#print ('Total number of train samples:',len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c91fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(samples):\n",
    "    data = shuffle(samples,random_state=2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0142dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data,batch_size=BATCH_SIZE,temporal_padding='same',shuffle=True):               \n",
    "    num_samples = len(data)\n",
    "    if shuffle:\n",
    "        data = shuffle_data(data)\n",
    "    while True:   \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            #print ('starting index: ', offset) \n",
    "            batch_samples = data[offset:offset+batch_size]\n",
    "            \n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            for batch_sample in batch_samples: \n",
    "                #print(batch_sample)\n",
    "                # Load image (X)\n",
    "                x = batch_sample[0] #image\n",
    "                y = batch_sample[1] #label\n",
    "                temp_data_list = []\n",
    "                for img in x:\n",
    "                    try:\n",
    "                        img = np.load(img)                        \n",
    "                        temp_data_list.append(img)\n",
    "                    except Exception as e:\n",
    "                        print (e)\n",
    "                        print ('error reading in frame: ',img)                      \n",
    "\n",
    "                X_train.append(temp_data_list)\n",
    "                y_train.append(y)\n",
    "\n",
    "            X_train = np.array(X_train)   \n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "        \n",
    "            print(X_train.shape)               \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "train_generator = data_generator(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "test_generator = data_generator(test_data,batch_size=BATCH_SIZE,shuffle=False) \n",
    "#x,y = next(train_generator)\n",
    "#xx,yy = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f849eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        Conv2D(32, (3,3), activation='relu'), \n",
    "        input_shape=(8, 13, 21, 1))\n",
    "    )\n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        Conv2D(64, (3,3), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        MaxPooling2D()\n",
    "        )\n",
    "    ) \n",
    "          \n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        Flatten()\n",
    "        )\n",
    "    )        \n",
    "    model.add(LSTM(64, activation='relu', return_sequences=False, recurrent_dropout=0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='Huber', optimizer=Adam(), metrics=['mean_squared_error'])\n",
    "    model.summary()\n",
    "    return model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Starting training; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"cp.ckpt\"\n",
    "earlyStop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = tf.keras.models.load_model('./cp.ckpt/')\n",
    "\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch=(len(train_data)/BATCH_SIZE),\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=(test_generator), validation_steps=(len(test_data)/BATCH_SIZE),\n",
    "                 use_multiprocessing=True,workers=6,\n",
    "                 callbacks=[cp_callback, csv_logger, earlyStop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879f5bc-ba3d-41ef-a51f-028c444e97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model = tf.keras.models.load_model('./cp.ckpt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "truthB = []\n",
    "predB = []\n",
    "\n",
    "limit = NUMBER_TEST_SET/BATCH_SIZE\n",
    " \n",
    "batches = 0\n",
    "for i in test_generator:\n",
    "  predB.append(model.predict(i[0]))\n",
    "  truthB.append(i[1]) \n",
    "  batches += 1\n",
    "  if batches > (NUMBER_TEST_SET/BATCH_SIZE)-1:\n",
    "    break\n",
    "\n",
    "predBATCHED = np.concatenate(predB)\n",
    "truthBATCHED = np.concatenate(truthB)\n",
    "\n",
    "df_predict2 = pd.DataFrame(predBATCHED, columns=['cotBeta'])\n",
    "df_true = pd.DataFrame(truthBATCHED, columns=['cotBeta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_true['cotBeta']-df_predict2['cotBeta'], kde=False, bins=50)\n",
    "plt.xlabel('cotBeta residual')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlim([-.05,.05])\n",
    "plt.title('Cot Beta Residual')\n",
    "plt.savefig('cotBeta-resolution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a59228-cdd4-451f-8a1b-c090d886571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict2.to_csv('predictions.csv')\n",
    "df_true.to_csv('trueLabels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
