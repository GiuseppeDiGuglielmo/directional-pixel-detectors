{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f683539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 11:31:12.325640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:15.589934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:15.591330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, TimeDistributed, LSTM, Conv3D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import CSVLogger\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import copy\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 50\n",
    "NUMBER_TEST_SET = 72000 #will do train/test split before this, and pass already-made sets in\n",
    "TEMPORAL_LENGTH = 8 #use first 8 frames (these are 16 frames in each video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed62e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_generator(data_path,data_files,temporal_stride=1,temporal_length=TEMPORAL_LENGTH):\n",
    "    #print(data_files)\n",
    "    for f in data_files: \n",
    "        tmp_df = pd.read_csv(os.path.join(data_path,f), sep=',')\n",
    "        label_list = list(tmp_df['label'])  \n",
    "        total_images = len(label_list) \n",
    "        if total_images==temporal_length: \n",
    "            num_samples = int((total_images-temporal_length)/temporal_stride)+1\n",
    "            #print ('num of frames: {}: {}'.format(f,num_samples))\n",
    "            img_list = list(tmp_df['FileName'])\n",
    "        else: # if the number of frames < than temporal length , discard it\n",
    "            print ('num of frames is less than temporal length; hence discarding this file-{}'.format(f))\n",
    "            continue\n",
    "\n",
    "        start_frame = 0\n",
    "        samples = deque()  \n",
    "        samp_count=0  \n",
    "        for img in img_list:\n",
    "            samples.append(img)\n",
    "            if len(samples)==temporal_length: \n",
    "                samples_c=copy.deepcopy(samples) \n",
    "                samp_count+=1\n",
    "                for t in range(temporal_stride): \n",
    "                    samples.popleft()\n",
    "                yield samples_c,label_list[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e6b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(data_cat='train',temporal_stride=1,temporal_length=TEMPORAL_LENGTH):\n",
    "    data_path = os.path.join('/uscms_data/d3/jieun201/YOURWORKINGAREA/data_files',data_cat)\n",
    "    data_files = os.listdir(data_path)\n",
    "    #generator to read the samples\n",
    "    file_gen = file_generator(data_path,data_files,temporal_stride,temporal_length)\n",
    "    iterator = True\n",
    "    data_list = []\n",
    "    while iterator:\n",
    "        try:\n",
    "            x,y = next(file_gen)\n",
    "            x=list(x)\n",
    "            #print(x)\n",
    "            data_list.append([x,y])\n",
    "        except Exception as e:\n",
    "            print ('Exception: ',e)\n",
    "            iterator = False\n",
    "            print ('end of data generator')\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425c3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception:  \n",
      "end of data generator\n"
     ]
    }
   ],
   "source": [
    "train_data = load_samples(data_cat='train',temporal_stride=1,temporal_length=TEMPORAL_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e042abd7-27a2-4958-a570-c6e9525d25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uscms_data/d3/jieun201/YOURWORKINGAREA/data_files/train\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join('/uscms_data/d3/jieun201/YOURWORKINGAREA/data_files','train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9f6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception:  \n",
      "end of data generator\n"
     ]
    }
   ],
   "source": [
    "test_data = load_samples(data_cat='test',temporal_stride=1,temporal_length=TEMPORAL_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc52f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train samples: 288000\n"
     ]
    }
   ],
   "source": [
    "print ('Total number of train samples:',len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed09b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame00.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame01.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame02.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame03.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame04.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame05.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame06.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures/d16111cluster0/event000000_frame07.npy'],\n",
       " -0.1132745164574143]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08067eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test samples: 72000\n"
     ]
    }
   ],
   "source": [
    "print ('Total number of test samples:',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795e0e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame00.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame01.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame02.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame03.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame04.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame05.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame06.npy',\n",
       "  '/uscms_data/d3/jieun201/YOURWORKINGAREA/figures-test/cluster0/event000000_frame07.npy'],\n",
       " 0.0806657911875553]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c91fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(samples):\n",
    "    data = shuffle(samples,random_state=2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0142dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data,batch_size=BATCH_SIZE,temporal_padding='same',shuffle=True):               \n",
    "    num_samples = len(data)\n",
    "    if shuffle:\n",
    "        data = shuffle_data(data)\n",
    "    while True:   \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            #print ('starting index: ', offset) \n",
    "            batch_samples = data[offset:offset+batch_size]\n",
    "            \n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            for batch_sample in batch_samples: \n",
    "                #print(batch_sample)\n",
    "                # Load image (X)\n",
    "                x = batch_sample[0] #image\n",
    "                y = batch_sample[1] #label\n",
    "                temp_data_list = []\n",
    "                for img in x:\n",
    "                    try:\n",
    "                        img = np.load(img)                        \n",
    "                        temp_data_list.append(img)\n",
    "                    except Exception as e:\n",
    "                        print (e)\n",
    "                        print ('error reading in frame: ',img)                      \n",
    "\n",
    "                X_train.append(temp_data_list)\n",
    "                y_train.append(y)\n",
    "\n",
    "            X_train = np.array(X_train)   \n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "        \n",
    "            print(X_train.shape)               \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea2200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(train_data))\n",
    "#print(len(test_data))\n",
    "\n",
    "#train_generator = data_generator(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "test_generator = data_generator(test_data,batch_size=BATCH_SIZE,shuffle=False) \n",
    "#x,y = next(train_generator)\n",
    "#xx,yy = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f849eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 23:50:59.206350: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-07 23:50:59.211132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 23:50:59.212737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 23:50:59.213895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 23:51:01.495323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 23:51:01.496697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 23:51:01.497909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-07 23:51:01.499034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10775 MB memory:  -> device: 0, name: Tesla K40m, pci bus id: 0000:00:07.0, compute capability: 3.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 8, 11, 19, 16)    160       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 8, 9, 17, 32)     4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 8, 4, 8, 32)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 8, 1024)          0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                278784    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,697\n",
      "Trainable params: 285,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        Conv2D(16, (3,3), activation='relu'), \n",
    "        input_shape=(8, 13, 21, 1))\n",
    "    )\n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        Conv2D(32, (3,3), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        MaxPooling2D()\n",
    "        )\n",
    "    ) \n",
    "          \n",
    "    model.add(\n",
    "    TimeDistributed(\n",
    "        Flatten()\n",
    "        )\n",
    "    )        \n",
    "    model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=Adam(), metrics=['mean_squared_error'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63f2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Starting training; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdaa0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"cp.ckpt\"\n",
    "earlyStop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2b9ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 11:31:23.348859: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-08 11:31:23.351213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:23.352641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:23.353902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:34.974312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:34.976212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:34.977532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-08 11:31:34.979258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10775 MB memory:  -> device: 0, name: Tesla K40m, pci bus id: 0000:00:09.0, compute capability: 3.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "#rom keras.models import load_model\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('./cp.ckpt/')\n",
    "\n",
    "#hist = model.fit(train_generator,\n",
    " #                steps_per_epoch=(len(train_data)/BATCH_SIZE),\n",
    "  #               epochs=EPOCHS,\n",
    "   #              validation_data=(test_generator), validation_steps=(len(test_data)/BATCH_SIZE),\n",
    "    #             use_multiprocessing=True,workers=6,\n",
    "     #            callbacks=[cp_callback, csv_logger, earlyStop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcdb2863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 8, 13, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 11:50:18.637685: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-05-08 11:50:32.550408: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2022-05-08 11:50:32.644231: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n",
      "(256, 8, 13, 21)\n"
     ]
    }
   ],
   "source": [
    "truthB = []\n",
    "predB = []\n",
    "\n",
    "limit = NUMBER_TEST_SET/BATCH_SIZE\n",
    "\n",
    "batches = 0\n",
    "for i in test_generator:\n",
    "  predB.append(model.predict(i[0]))\n",
    "  truthB.append(i[1]) \n",
    "  batches += 1\n",
    "  if batches > (NUMBER_TEST_SET/BATCH_SIZE)-1:\n",
    "    break\n",
    "\n",
    "predBATCHED = np.concatenate(predB)\n",
    "truthBATCHED = np.concatenate(truthB)\n",
    "\n",
    "df_predict2 = pd.DataFrame(predBATCHED, columns=['cotBeta'])\n",
    "df_true = pd.DataFrame(truthBATCHED, columns=['cotBeta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5def2da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jieun201/.local/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_true['cotBeta']-df_predict2['cotBeta'], kde=False, bins=50)\n",
    "plt.xlabel('cotBeta residual')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlim([-.3,.3])\n",
    "plt.title('Cot Beta Residual')\n",
    "plt.savefig('cotBeta-resolution.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
